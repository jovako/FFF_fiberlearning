model: fff.FreeFormInjectiveFlow

noise: 0.01
load_subject_model: True
latent_distribution:
  name: "transformed_normal"
data_set:
  name: saved_mnist
  root: data/cc_mnist
  conditional: True

loss_weights:
  nll: 1
  latent_reconstruction: 10
  #noisy_reconstruction: 100
  #masked_reconstruction: 1
  fiber_loss: 10
  #z_sample_reconstruction: 1000
max_epochs: 100
#warm_up_epochs: [15, 100]
#warm_up_fiber: [50, 60]

train_models: False
train_transform: True
vae: True
models:
  - name: fff.model.ConvolutionalNeuralNetwork
    latent_dim: 100
    ch_factor: 32
    encoder_spec: 
      - [3, 4, 2, 1]
      - [6, 4, 2, 1]
      - [8, 4, 2, 1]
      - [10, 4, 2, 1]
    decoder_spec:
      - [10, 4]
      - [8, 3, 2, 1]
      - [6, 3, 2, 1, 1]
      - [3, 3, 2, 1, 1]
  - name: fff.model.VarResNet
    latent_dim: &latent_dim 54
    layers_spec:
      - [512, 512, 512]
      - [512, 512, 512]
      - [512, 512, 512]
transform:
  name: fff.model.ResNet
  data_dim: *latent_dim
  latent_dim: 3
  layers_spec:
    - [512, 512]
    - [512, 512]
    - [512, 512]

lr_scheduler: "onecyclelr"
optimizer:
  name: adam
  lr: 0.001
  #weight_decay: 0.0002
gradient_clip: 3.0

batch_size: 512
load_models_path: "lightning_logs/Cnn_vae/version_2/checkpoints/last.ckpt"
  #load_transform_path: "lightning_logs/16_f48f_011_log/version_0/checkpoints/last.ckpt"
