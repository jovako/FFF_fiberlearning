{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24f00e15-782e-4285-9f75-5a8baae2613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import torch\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b85fb2c7-9ea4-4cfb-b804-fe589936ccb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hd/hd_hd/hd_gu452/miniconda3/envs/nnssl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded checkpoint: /home/hd/hd_hd/hd_gu452/.cache/huggingface/hub/models--AnonRes--ResEncL-OpenMind-MAE/snapshots/2fa30f642db8e9b2c04bdfb526582fed86ec5850/checkpoint_final.pth\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Example: download the checkpoint_final.pth\n",
    "repo_id = \"AnonRes/ResEncL-OpenMind-MAE\"  # replace with actual repo name\n",
    "filename = \"checkpoint_final.pth\"\n",
    "\n",
    "checkpoint_path = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "print(\"Downloaded checkpoint:\", checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d34f950-d0d0-4238-8317-5128962bde6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### Loading pretrained weights from file  /home/hd/hd_hd/hd_gu452/.cache/huggingface/hub/models--AnonRes--ResEncL-OpenMind-MAE/snapshots/2fa30f642db8e9b2c04bdfb526582fed86ec5850/checkpoint_final.pth ###################\n",
      "Below is the list of overlapping blocks in pretrained model and nnUNet architecture:\n",
      "encoder.stem.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])\n",
      "encoder.stem.convs.0.conv.bias shape torch.Size([32])\n",
      "encoder.stem.convs.0.norm.weight shape torch.Size([32])\n",
      "encoder.stem.convs.0.norm.bias shape torch.Size([32])\n",
      "encoder.stem.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])\n",
      "encoder.stem.convs.0.all_modules.0.bias shape torch.Size([32])\n",
      "encoder.stem.convs.0.all_modules.1.weight shape torch.Size([32])\n",
      "encoder.stem.convs.0.all_modules.1.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.conv.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv1.conv.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.norm.weight shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.norm.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.0.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.1.weight shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.1.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.conv.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv2.conv.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.norm.weight shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.norm.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.0.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.1.weight shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.1.bias shape torch.Size([32])\n",
      "encoder.stages.1.blocks.0.conv1.conv.weight shape torch.Size([64, 32, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv1.conv.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.norm.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.norm.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.0.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.1.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.1.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv2.conv.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.norm.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.norm.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.0.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.1.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.1.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.conv.weight shape torch.Size([64, 32, 1, 1, 1])\n",
      "encoder.stages.1.blocks.0.skip.1.norm.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.norm.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.all_modules.0.weight shape torch.Size([64, 32, 1, 1, 1])\n",
      "encoder.stages.1.blocks.0.skip.1.all_modules.1.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.all_modules.1.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv1.conv.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.norm.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.norm.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.0.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.1.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.1.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv2.conv.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.norm.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.norm.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.0.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.1.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.1.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv1.conv.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.norm.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.norm.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.0.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.1.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.1.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv2.conv.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.norm.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.norm.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.0.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.1.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.1.bias shape torch.Size([64])\n",
      "encoder.stages.2.blocks.0.conv1.conv.weight shape torch.Size([128, 64, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv1.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv2.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.conv.weight shape torch.Size([128, 64, 1, 1, 1])\n",
      "encoder.stages.2.blocks.0.skip.1.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.all_modules.0.weight shape torch.Size([128, 64, 1, 1, 1])\n",
      "encoder.stages.2.blocks.0.skip.1.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv1.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv2.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv1.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv2.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv1.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv2.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.3.blocks.0.conv1.conv.weight shape torch.Size([256, 128, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv1.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv2.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.conv.weight shape torch.Size([256, 128, 1, 1, 1])\n",
      "encoder.stages.3.blocks.0.skip.1.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.all_modules.0.weight shape torch.Size([256, 128, 1, 1, 1])\n",
      "encoder.stages.3.blocks.0.skip.1.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv1.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv2.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv1.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv2.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv1.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv2.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv1.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv2.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv1.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv2.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.4.blocks.0.conv1.conv.weight shape torch.Size([320, 256, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.conv.weight shape torch.Size([320, 256, 1, 1, 1])\n",
      "encoder.stages.4.blocks.0.skip.1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.all_modules.0.weight shape torch.Size([320, 256, 1, 1, 1])\n",
      "encoder.stages.4.blocks.0.skip.1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stem.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])\n",
      "decoder.encoder.stem.convs.0.conv.bias shape torch.Size([32])\n",
      "decoder.encoder.stem.convs.0.norm.weight shape torch.Size([32])\n",
      "decoder.encoder.stem.convs.0.norm.bias shape torch.Size([32])\n",
      "decoder.encoder.stem.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])\n",
      "decoder.encoder.stem.convs.0.all_modules.0.bias shape torch.Size([32])\n",
      "decoder.encoder.stem.convs.0.all_modules.1.weight shape torch.Size([32])\n",
      "decoder.encoder.stem.convs.0.all_modules.1.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.conv.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.conv.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.norm.weight shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.norm.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.all_modules.0.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.all_modules.1.weight shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.all_modules.1.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.conv.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.conv.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.norm.weight shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.norm.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.all_modules.0.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.all_modules.1.weight shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.all_modules.1.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.conv.weight shape torch.Size([64, 32, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.conv.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.norm.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.norm.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.all_modules.0.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.conv.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.norm.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.norm.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.all_modules.0.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.conv.weight shape torch.Size([64, 32, 1, 1, 1])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.norm.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.norm.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.all_modules.0.weight shape torch.Size([64, 32, 1, 1, 1])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.conv.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.norm.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.norm.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.all_modules.0.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.conv.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.norm.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.norm.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.all_modules.0.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.conv.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.norm.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.norm.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.all_modules.0.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.conv.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.norm.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.norm.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.all_modules.0.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.conv.weight shape torch.Size([128, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.conv.weight shape torch.Size([128, 64, 1, 1, 1])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.all_modules.0.weight shape torch.Size([128, 64, 1, 1, 1])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.conv.weight shape torch.Size([256, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.conv.weight shape torch.Size([256, 128, 1, 1, 1])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.all_modules.0.weight shape torch.Size([256, 128, 1, 1, 1])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.conv.weight shape torch.Size([320, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.conv.weight shape torch.Size([320, 256, 1, 1, 1])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.all_modules.0.weight shape torch.Size([320, 256, 1, 1, 1])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])\n",
      "decoder.stages.0.convs.0.conv.bias shape torch.Size([320])\n",
      "decoder.stages.0.convs.0.norm.weight shape torch.Size([320])\n",
      "decoder.stages.0.convs.0.norm.bias shape torch.Size([320])\n",
      "decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])\n",
      "decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])\n",
      "decoder.stages.1.convs.0.conv.bias shape torch.Size([256])\n",
      "decoder.stages.1.convs.0.norm.weight shape torch.Size([256])\n",
      "decoder.stages.1.convs.0.norm.bias shape torch.Size([256])\n",
      "decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])\n",
      "decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])\n",
      "decoder.stages.2.convs.0.conv.bias shape torch.Size([128])\n",
      "decoder.stages.2.convs.0.norm.weight shape torch.Size([128])\n",
      "decoder.stages.2.convs.0.norm.bias shape torch.Size([128])\n",
      "decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])\n",
      "decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])\n",
      "decoder.stages.3.convs.0.conv.bias shape torch.Size([64])\n",
      "decoder.stages.3.convs.0.norm.weight shape torch.Size([64])\n",
      "decoder.stages.3.convs.0.norm.bias shape torch.Size([64])\n",
      "decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])\n",
      "decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])\n",
      "decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])\n",
      "decoder.stages.4.convs.0.conv.bias shape torch.Size([32])\n",
      "decoder.stages.4.convs.0.norm.weight shape torch.Size([32])\n",
      "decoder.stages.4.convs.0.norm.bias shape torch.Size([32])\n",
      "decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])\n",
      "decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])\n",
      "decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])\n",
      "decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])\n",
      "decoder.transpconvs.0.weight shape torch.Size([320, 320, 2, 2, 2])\n",
      "decoder.transpconvs.0.bias shape torch.Size([320])\n",
      "decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])\n",
      "decoder.transpconvs.1.bias shape torch.Size([256])\n",
      "decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])\n",
      "decoder.transpconvs.2.bias shape torch.Size([128])\n",
      "decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])\n",
      "decoder.transpconvs.3.bias shape torch.Size([64])\n",
      "decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])\n",
      "decoder.transpconvs.4.bias shape torch.Size([32])\n",
      "################### Done ###################\n"
     ]
    }
   ],
   "source": [
    "from nnssl.architectures.architecture_registry import get_res_enc_l\n",
    "from nnssl.run.load_pretrained_weights import load_pretrained_weights\n",
    "import torch\n",
    "\n",
    "# Instantiate model\n",
    "model = get_res_enc_l(num_input_channels=1, num_output_channels=1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load pretrained weights\n",
    "load_pretrained_weights(model, checkpoint_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e51e891-8775-47f6-9dbd-2e3944f14925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def torch_resize(x, size, mode=\"bilinear\", align_corners=False):\n",
    "    \"\"\"\n",
    "    Resize a 2D or 3D tensor with edge-padding (replicate), similar to\n",
    "    skimage.transform.resize(..., mode=\"edge\").\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        Input tensor of shape:\n",
    "        - 3D: (C, H, W) or (C, D, H, W)\n",
    "        - 4D: (N, C, H, W)\n",
    "        - 5D: (N, C, D, H, W)\n",
    "    size : tuple\n",
    "        Target spatial size (H, W) or (D, H, W).\n",
    "    mode : str\n",
    "        Interpolation mode: \"nearest\", \"bilinear\" (2D), \"trilinear\" (3D).\n",
    "    align_corners : bool\n",
    "        Same as in torch.nn.functional.interpolate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Resized tensor with edge-padding behavior.\n",
    "    \"\"\"\n",
    "    ndim = x.ndim\n",
    "\n",
    "    # Ensure batch + channel dimensions\n",
    "    if ndim == 3:   # (C, H, W)\n",
    "        x = x.unsqueeze(0)   # -> (N, C, H, W)\n",
    "    elif ndim == 4 and x.shape[1] != 1 and x.shape[1] != 3:\n",
    "        # Could be (C, D, H, W), add batch dim\n",
    "        x = x.unsqueeze(0)   # -> (N, C, D, H, W)\n",
    "\n",
    "    # Pad if target size is bigger than input\n",
    "    in_size = x.shape[-len(size):]\n",
    "    pad_sizes = []\n",
    "    for in_dim, out_dim in zip(reversed(in_size), reversed(size)):\n",
    "        pad = max(0, out_dim - in_dim)\n",
    "        pad_sizes.extend([0, pad])\n",
    "    if any(pad_sizes):\n",
    "        x = F.pad(x, pad_sizes, mode=\"replicate\")\n",
    "\n",
    "    # Interpolate to exact target size\n",
    "    x = F.interpolate(x, size=size, mode=mode, align_corners=align_corners)\n",
    "\n",
    "    # Squeeze back if input had no batch\n",
    "    if ndim == 3 or (ndim == 4 and x.shape[0] == 1):\n",
    "        x = x.squeeze(0)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resample_data_or_seg(\n",
    "    data: torch.Tensor,\n",
    "    new_shape: tuple,\n",
    "    is_seg: bool = False,\n",
    "    order: int = 3,\n",
    "    order_z: int = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    separate_z=True will resample with order 0 along z\n",
    "    :param data:\n",
    "    :param new_shape:\n",
    "    :param is_seg:\n",
    "    :param order:\n",
    "    :param do_separate_z:\n",
    "    :param order_z: only applies if do_separate_z is True\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert data.ndim == 4, \"data must be (c, x, y, z)\"\n",
    "    assert len(new_shape) == data.ndim - 1\n",
    "\n",
    "    if is_seg:\n",
    "        resize_fn = torch_resize # This may be inaccurate to the numpy version but not used anyways\n",
    "    else:\n",
    "        resize_fn = torch_resize\n",
    "    dtype_data = data.dtype\n",
    "    shape = torch.Size(data[0].shape)\n",
    "    new_shape = torch.Size(new_shape)\n",
    "    if shape != new_shape:\n",
    "        data = data.float()\n",
    "            # print(\"no separate z, order\", order)\n",
    "        reshaped = []\n",
    "        for c in range(data.shape[0]):\n",
    "            reshaped.append(resize_fn(data[c], new_shape)[None])\n",
    "        reshaped_final_data = torch.stack(reshaped, dim=0)\n",
    "        return reshaped_final_data.to(dtype_data)\n",
    "    else:\n",
    "        # print(\"no resampling necessary\")\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50953215-708c-4e31-96f8-ff877c55afb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnssl_raw is not defined and nnssl_raw can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n",
      "nnssl_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "nnssl_results is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n"
     ]
    }
   ],
   "source": [
    "from nnssl.experiment_planning.experiment_planners.default_experiment_planner import ExperimentPlanner\n",
    "from nnssl.experiment_planning.experiment_planners.plan import ConfigurationPlan, Plan\n",
    "from nnssl.preprocessing.preprocessors.abstract_preprocessor import Preprocessors\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_configuration_plan(\n",
    "    data_identifier: str = \"default\",\n",
    ") -> ConfigurationPlan:\n",
    "\n",
    "    resampling_data = resample_data_or_seg\n",
    "    resampling_data_kwargs = {\n",
    "        \"is_seg\": False,\n",
    "        \"order\": 3,\n",
    "        \"order_z\": 0,\n",
    "    }\n",
    "    resampling_seg = resample_data_or_seg\n",
    "    resampling_seg_kwargs = {\n",
    "        \"is_seg\": True,\n",
    "        \"order\": 1,\n",
    "        \"order_z\": 0,\n",
    "    }\n",
    "    \n",
    "    spacing = [1, 1, 1]\n",
    "    spacing_style = \"onemmiso\"\n",
    "\n",
    "\n",
    "    plan = {\n",
    "        \"data_identifier\": data_identifier,\n",
    "        \"preprocessor_name\": Preprocessors.DEFAULT.value,\n",
    "        \"spacing_style\": spacing_style,\n",
    "        \"spacing\": spacing,\n",
    "        \"normalization_schemes\": [\"ZScoreNormalization\"],\n",
    "        \"use_mask_for_norm\": [False],\n",
    "        \"resampling_fn_data\": resampling_data,\n",
    "        \"resampling_fn_data_kwargs\": resampling_data_kwargs,\n",
    "        \"resampling_fn_mask\": resampling_seg,\n",
    "        \"resampling_fn_mask_kwargs\": resampling_seg_kwargs,\n",
    "    }\n",
    "\n",
    "    return ConfigurationPlan(**plan)\n",
    "\n",
    "def get_full_plan():\n",
    "    target_spacing = torch.Tensor([1, 1, 1])\n",
    "\n",
    "    max_spacing_axis = torch.argmax(target_spacing)\n",
    "    remaining_axes = [i for i in list(range(3)) if i != max_spacing_axis]\n",
    "    transpose_forward = torch.Tensor([max_spacing_axis] + remaining_axes).int()\n",
    "    transpose_backward = [torch.argwhere(torch.Tensor(transpose_forward) == i)[0][0] for i in range(3)]\n",
    "    median_spacing = torch.Tensor([1,1,1])[transpose_forward]\n",
    "    plans = Plan(\n",
    "        **{\n",
    "            \"dataset_name\": None,\n",
    "            \"plans_name\": \"default_plan\",\n",
    "            \"original_median_spacing_after_transp\": [float(i) for i in median_spacing],\n",
    "            \"image_reader_writer\": None,\n",
    "            \"transpose_forward\": [int(i) for i in transpose_forward],\n",
    "            \"transpose_backward\": [int(i) for i in transpose_backward],\n",
    "            \"configurations\": {\"onemmiso\": get_configuration_plan()},\n",
    "            \"experiment_planner_used\": None,\n",
    "        }\n",
    "    )\n",
    "    return plans\n",
    "    \n",
    "plan = get_full_plan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de5e408-7a79-49f1-ab30-e2ff729c3810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan(dataset_name=None, plans_name='default_plan', original_median_spacing_after_transp=[1.0, 1.0, 1.0], image_reader_writer=None, transpose_forward=[0, 1, 2], transpose_backward=[0, 1, 2], configurations={'onemmiso': ConfigurationPlan(data_identifier='default', preprocessor_name='DefaultPreprocessor', spacing_style='onemmiso', normalization_schemes=['ZScoreNormalization'], use_mask_for_norm=[False], resampling_fn_data=<function resample_data_or_seg at 0x145d2b2e0820>, resampling_fn_data_kwargs={'is_seg': False, 'order': 3, 'order_z': 0}, resampling_fn_mask=<function resample_data_or_seg at 0x145d2b2e0820>, resampling_fn_mask_kwargs={'is_seg': True, 'order': 1, 'order_z': 0}, spacing=[1, 1, 1], patch_size=None)}, experiment_planner_used=None)\n"
     ]
    }
   ],
   "source": [
    "print(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbacc657-cdae-4af4-929e-be400a87f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnssl.preprocessing.resampling.default_resampling import compute_new_shape, get_resampling_scheme\n",
    "from dataclasses import field\n",
    "from acvl_utils.cropping_and_padding.bounding_boxes import crop_to_bbox, bounding_box_to_slice\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def convert_dtype(image: torch.Tensor, target_dtype) -> torch.Tensor:\n",
    "    return image.to(target_dtype)\n",
    "\n",
    "def z_score_normalization(\n",
    "    image: torch.Tensor, use_mask_for_norm: bool, non_zero_mask: torch.Tensor, target_dtype\n",
    ") -> torch.Tensor:\n",
    "    image = convert_dtype(image, target_dtype)\n",
    "    if use_mask_for_norm:\n",
    "        mask = non_zero_mask >= 0\n",
    "        mean = image[mask].mean()\n",
    "        std = image[mask].std()\n",
    "        image[mask] = (image[mask] - mean) / max(std, 1e-8)\n",
    "    else:\n",
    "        mean = image.mean()\n",
    "        std = image.std()\n",
    "        image = (image - mean) / max(std, 1e-8)\n",
    "    return image\n",
    "\n",
    "def normalize_torch(\n",
    "    data: torch.Tensor,\n",
    "    non_zero_mask: torch.Tensor,\n",
    "    normalization_schemes: list[str],\n",
    "    use_mask_for_norm: list[bool],\n",
    "):\n",
    "    # iterate over images\n",
    "    for c in range(data.shape[0]):\n",
    "        if normalization_schemes[c] == \"ZScoreNormalization\":\n",
    "            data[c] = z_score_normalization(data[c], use_mask_for_norm[c], non_zero_mask[c], data.dtype)\n",
    "        else:\n",
    "            raise(NotImplementedError())\n",
    "    return data\n",
    "\n",
    "from acvl_utils.cropping_and_padding.bounding_boxes import crop_to_bbox, bounding_box_to_slice\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def create_nonzero_mask_torch(data: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create a mask that is True where the data is nonzero, and fills small holes.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): Input tensor of shape (C, X, Y, Z) or (C, X, Y).\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Boolean mask of shape (X, Y, Z) or (X, Y).\n",
    "    \"\"\"\n",
    "    assert data.ndim in (3, 4), \"data must have shape (C, X, Y, Z) or (C, X, Y)\"\n",
    "\n",
    "    # Collapse channels -> OR across channels\n",
    "    nonzero_mask = (data != 0).any(dim=0)\n",
    "\n",
    "    # Fill holes: morphological closing (dilation then erosion)\n",
    "    # Works for both 2D and 3D\n",
    "    dims = nonzero_mask.ndim\n",
    "    if dims == 2:  # (X, Y)\n",
    "        kernel = torch.ones((1, 1, 3, 3), device=data.device, dtype=torch.float32)\n",
    "        mask = nonzero_mask[None, None].float()\n",
    "        dilated = (F.conv2d(mask, kernel, padding=1) > 0).float()\n",
    "        closed = (F.conv2d(dilated, kernel, padding=1) == 9).squeeze(0).squeeze(0).bool()\n",
    "    elif dims == 3:  # (X, Y, Z)\n",
    "        kernel = torch.ones((1, 1, 3, 3, 3), device=data.device, dtype=torch.float32)\n",
    "        mask = nonzero_mask[None, None].float()\n",
    "        dilated = (F.conv3d(mask, kernel, padding=1) > 0).float()\n",
    "        closed = (F.conv3d(dilated, kernel, padding=1) == 27).squeeze(0).squeeze(0).bool()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported dimensions\")\n",
    "\n",
    "    return closed\n",
    "\n",
    "def get_bbox_from_mask(mask: torch.Tensor) -> list[list[int]]:\n",
    "    \"\"\"\n",
    "    ALL bounding boxes in acvl_utils and nnU-Netv2 are half open interval [start, end)!\n",
    "    - Alignment with Python Slicing\n",
    "    - Ease of Subdivision\n",
    "    - Consistency in Multi-Dimensional Arrays\n",
    "    - Precedent in Computer Graphics\n",
    "    https://chatgpt.com/share/679203ec-3fbc-8013-a003-13a7adfb1e73\n",
    "\n",
    "    this implementation uses less ram than the np.where one and is faster as well IF we expect the bounding box to\n",
    "    be close to the image size. If it's not it's likely slower!\n",
    "\n",
    "    :param mask:\n",
    "    :param outside_value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    Z, X, Y = mask.shape\n",
    "    minzidx, maxzidx, minxidx, maxxidx, minyidx, maxyidx = 0, Z, 0, X, 0, Y\n",
    "    zidx = list(range(Z))\n",
    "    for z in zidx:\n",
    "        if torch.any(mask[z]):\n",
    "            minzidx = z\n",
    "            break\n",
    "    for z in zidx[::-1]:\n",
    "        if torch.any(mask[z]):\n",
    "            maxzidx = z + 1\n",
    "            break\n",
    "\n",
    "    xidx = list(range(X))\n",
    "    for x in xidx:\n",
    "        if torch.any(mask[:, x]):\n",
    "            minxidx = x\n",
    "            break\n",
    "    for x in xidx[::-1]:\n",
    "        if torch.any(mask[:, x]):\n",
    "            maxxidx = x + 1\n",
    "            break\n",
    "\n",
    "    yidx = list(range(Y))\n",
    "    for y in yidx:\n",
    "        if torch.any(mask[:, :, y]):\n",
    "            minyidx = y\n",
    "            break\n",
    "    for y in yidx[::-1]:\n",
    "        if torch.any(mask[:, :, y]):\n",
    "            maxyidx = y + 1\n",
    "            break\n",
    "    return [[minzidx, maxzidx], [minxidx, maxxidx], [minyidx, maxyidx]]\n",
    "\n",
    "\n",
    "\n",
    "def crop_to_nonzero(data, masks: list[torch.Tensor] | None = None, nonzero_label=-1):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data:\n",
    "    :param seg:\n",
    "    :param nonzero_label: this will be written into the segmentation map\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    nonzero_mask = create_nonzero_mask_torch(data)\n",
    "    bbox = get_bbox_from_mask(nonzero_mask)\n",
    "\n",
    "    slicer = bounding_box_to_slice(bbox)\n",
    "    data = data[tuple([slice(None), *slicer])]\n",
    "    nonzero_mask = nonzero_mask[slicer][None]\n",
    "\n",
    "    slicer = (slice(None),) + slicer\n",
    "    if masks is not None and len(masks) > 0:\n",
    "        for cnt, mask in enumerate(masks):\n",
    "            masks[cnt] = mask[slicer]\n",
    "            masks[cnt][(masks[cnt] == 0) & (~nonzero_mask)] = nonzero_label\n",
    "\n",
    "    else:\n",
    "        masks = [torch.where(nonzero_mask, torch.zeros(1).int(), int(nonzero_label))]\n",
    "    return data, masks, bbox\n",
    "\n",
    "def preprocess_case(\n",
    "    data,\n",
    "    masks=None,\n",
    "    plan = get_full_plan(),\n",
    "    properties=None,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    # let's not mess up the inputs!\n",
    "    data = data.clone()\n",
    "    if masks is not None:\n",
    "        for mask in masks:\n",
    "            assert (\n",
    "                data.shape[1:] == mask.shape[1:]\n",
    "            ), \"Shape mismatch between image and associated masks. Please fix your dataset and make use of the --verify_dataset_integrity flag to ensure everything is correct\"\n",
    "        masks = [mask.clone() for mask in masks]\n",
    "\n",
    "    has_masks = masks is not None\n",
    "\n",
    "    # apply transpose_forward, this also needs to be applied to the spacing!\n",
    "    data = data.permute([0, *[i + 1 for i in plan.transpose_forward]])\n",
    "    if has_masks:\n",
    "        for cnt, mask in enumerate(masks):\n",
    "            masks[cnt] = mask.transpose([0, *[i + 1 for i in plan.transpose_forward]])\n",
    "    original_spacing = [properties[\"spacing\"][i] for i in plan.transpose_forward]\n",
    "\n",
    "    # crop, remember to store size before cropping!\n",
    "    shape_before_cropping = data.shape[1:]\n",
    "    properties[\"shape_before_cropping\"] = shape_before_cropping\n",
    "    # this command will generate a segmentation. This is important because of the nonzero mask which we may need\n",
    "    data, masks, bbox = crop_to_nonzero(data, masks)\n",
    "    properties[\"bbox_used_for_cropping\"] = bbox\n",
    "    properties[\"shape_after_cropping_and_before_resampling\"] = data.shape[1:]\n",
    "\n",
    "    config_plan = plan[\"configurations\"][\"onemmiso\"]\n",
    "    # resample\n",
    "    target_spacing = config_plan.spacing  # this should already be transposed\n",
    "\n",
    "    if len(target_spacing) < len(data.shape[1:]):\n",
    "        # target spacing for 2d has 2 entries but the data and original_spacing have three because everything is 3d\n",
    "        # in 2d configuration we do not change the spacing between slices\n",
    "        target_spacing = [original_spacing[0]] + target_spacing\n",
    "    new_shape = compute_new_shape(data.shape[1:], original_spacing, target_spacing)\n",
    "\n",
    "    # normalize\n",
    "    # normalization MUST happen before resampling or we get huge problems with resampled nonzero masks no\n",
    "    # longer fitting the images perfectly!\n",
    "    norm_mask = masks[0]\n",
    "    data = normalize_torch(data, norm_mask, config_plan.normalization_schemes, config_plan.use_mask_for_norm)\n",
    "    old_shape = data.shape[1:]\n",
    "    resampling_fn = partial(\n",
    "        config_plan.resampling_fn_data, **config_plan.resampling_fn_data_kwargs\n",
    "    )\n",
    "    data = resampling_fn(data, new_shape)\n",
    "\n",
    "    if has_masks:\n",
    "        resampling_mask_fn = partial(\n",
    "            config_plan.resampling_fn_mask, **config_plan.resampling_fn_mask_kwargs\n",
    "        )\n",
    "        for cnt, mask in enumerate(masks):\n",
    "            masks[cnt] = resampling_mask_fn(mask, new_shape)\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"old shape: {old_shape}, new_shape: {new_shape}, old_spacing: {original_spacing}, \"\n",
    "            f\"new_spacing: {target_spacing}, fn_data: {config_plan.resampling_fn_data}\"\n",
    "        )\n",
    "    if not has_masks:\n",
    "        masks = None\n",
    "    return data, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5297a329-8506-4116-a360-46e505394ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import torch.nn.functional as F\n",
    "\n",
    "nii_path = \"/home/hd/hd_hd/hd_gu452/FFF_fiberlearning/notebooks/monai_models/openmind_diffusion_training/predictions/unet_3d_seed50851_size128x256x256_spacing1.25x1.00x1.00_20250929120942_rank0.nii.gz\"\n",
    "\n",
    "def load_nii_as_tensor(path, target_shape=(96, 96, 96)):\n",
    "    \"\"\"\n",
    "    Load a NIfTI file, normalize intensity, and resize to target shape.\n",
    "    Returns: torch.FloatTensor of shape (1, 1, D, H, W).\n",
    "    \"\"\"\n",
    "    img = nib.load(path).get_fdata()\n",
    "\n",
    "    tensor = torch.from_numpy(img).unsqueeze(0)  # (1,1,D,H,W)\n",
    "\n",
    "    data_properties = {\n",
    "        \"spacing\": [1, 1, 1],\n",
    "    }\n",
    "    \n",
    "    data, mask = preprocess_case(tensor, properties=data_properties)\n",
    "    data = data.unsqueeze(0)\n",
    "    # resize to model input shape\n",
    "    if target_shape is not None:\n",
    "        data = F.interpolate(data, size=target_shape, mode=\"trilinear\", align_corners=False)\n",
    "    return data.float().to(device)\n",
    "\n",
    "\n",
    "x = load_nii_as_tensor(nii_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba3d6849-b21a-4256-a483-8004f6c4cba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed /home/hd/hd_hd/hd_gu452/FFF_fiberlearning/notebooks/monai_models/openmind_diffusion_training/predictions/unet_3d_seed50851_size128x256x256_spacing1.25x1.00x1.00_20250929120942_rank0.nii.gz, embedding shape: (884736,)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(x)\n",
    "\n",
    "# example: get embeddings (flatten)\n",
    "embedding = output.view(-1).cpu().numpy()\n",
    "\n",
    "# save embedding as .npy\n",
    "base = os.path.basename(nii_path).replace(\".nii.gz\", \"\")\n",
    "\n",
    "print(f\"Processed {nii_path}, embedding shape: {embedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7aed9f1e-b855-4b84-94ff-4972ac3ad9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_orthogonal_views(volume):\n",
    "    \"\"\"\n",
    "    Show axial (top), coronal (front), and sagittal (side) views\n",
    "    from the center of a 3D MRI volume.\n",
    "\n",
    "    Args:\n",
    "        volume: 3D array-like (H, W, D) or 4D (C, H, W, D).\n",
    "    \"\"\"\n",
    "    # Ensure numpy\n",
    "    if isinstance(volume, torch.Tensor):\n",
    "        volume = volume.detach().cpu().numpy()\n",
    "    if volume.ndim == 4:  # remove channel if present\n",
    "        volume = volume[0]\n",
    "\n",
    "    # Shape: (H, W, D)\n",
    "    h, w, d = volume.shape\n",
    "\n",
    "    # Extract central slices\n",
    "    axial = volume[:, :, d // 2]     # top view\n",
    "    coronal = volume[:, w // 2, :]   # front view\n",
    "    sagittal = volume[h // 2, :, :]  # side view\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "    axes[0].imshow(axial.T, cmap=\"gray\", origin=\"lower\", vmin=0, vmax=1)\n",
    "    axes[0].set_title(\"Axial (Top)\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(coronal.T, cmap=\"gray\", origin=\"lower\", vmin=0, vmax=1)\n",
    "    axes[1].set_title(\"Coronal (Front)\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    axes[2].imshow(sagittal.T, cmap=\"gray\", origin=\"lower\", vmin=0, vmax=1)\n",
    "    axes[2].set_title(\"Sagittal (Side)\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "x_norm = (x - x.min())/(x.max() - x.min())\n",
    "visualize_orthogonal_views(x_norm.squeeze())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnssl",
   "language": "python",
   "name": "nnssl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
