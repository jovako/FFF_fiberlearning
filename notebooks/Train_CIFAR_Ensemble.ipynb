{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7335c70f-19ff-4499-8fba-0f73e78fac7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training model 0 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch   0 | Loss 1.3570 | Acc 50.42%:   0%|          | 0/200 [00:15<?, ?it/s]\u001b[A\n",
      "Epoch   0 | Loss 1.3570 | Acc 50.42%:   0%|          | 1/200 [00:15<50:21, 15.18s/it]\u001b[A\n",
      "Epoch   1 | Loss 0.8974 | Acc 68.32%:   0%|          | 1/200 [00:30<50:21, 15.18s/it]\u001b[A\n",
      "Epoch   1 | Loss 0.8974 | Acc 68.32%:   1%|          | 2/200 [00:30<50:06, 15.18s/it]\u001b[A\n",
      "                                                                                     \u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 148\u001b[0m\n\u001b[1;32m    144\u001b[0m         train_one_model(model_id, save_dir, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 148\u001b[0m     \u001b[43mtrain_ensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 144\u001b[0m, in \u001b[0;36mtrain_ensemble\u001b[0;34m(n_models, save_dir, device)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_ensemble\u001b[39m(\n\u001b[1;32m    139\u001b[0m     n_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m    140\u001b[0m     save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ensemble_resnet18_cifar\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    141\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m ):\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_models):\n\u001b[0;32m--> 144\u001b[0m         \u001b[43mtrain_one_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 120\u001b[0m, in \u001b[0;36mtrain_one_model\u001b[0;34m(model_id, save_dir, device, initial_lr, epochs, batch_size)\u001b[0m\n\u001b[1;32m    117\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    118\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 120\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    121\u001b[0m _, pred \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    122\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39meq(y)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# Ovadia et al. learning rate schedule\n",
    "# ----------------------------------------\n",
    "\n",
    "def update_lr(optimizer, epoch, initial_lr):\n",
    "    if epoch < 80:\n",
    "        lr = initial_lr\n",
    "    elif epoch < 120:\n",
    "        lr = initial_lr * 0.1\n",
    "    elif epoch < 160:\n",
    "        lr = initial_lr * 0.01\n",
    "    elif epoch < 180:\n",
    "        lr = initial_lr * 0.001\n",
    "    else:\n",
    "        lr = initial_lr * 0.0005\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# Build CIFAR-compatible torchvision ResNet18\n",
    "# ----------------------------------------\n",
    "\n",
    "def build_resnet18_cifar(dropout_p=0.0):\n",
    "    model = resnet18(weights=None)\n",
    "\n",
    "    # CIFAR modification: replace the first conv and remove maxpool\n",
    "    model.conv1 = nn.Conv2d(\n",
    "        3, 64, kernel_size=3, stride=1, padding=1, bias=False\n",
    "    )\n",
    "    model.maxpool = nn.Identity()\n",
    "\n",
    "    # Optional dropout: before FC only (Ovadia applies dropout everywhere,\n",
    "    # but you requested \"same as before\" -> minimal intervention)\n",
    "    if dropout_p > 0:\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    else:\n",
    "        model.fc = nn.Linear(512, 10)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# Train a single model\n",
    "# ----------------------------------------\n",
    "\n",
    "def train_one_model(model_id, save_dir, device=\"cuda\",\n",
    "                    initial_lr=1e-3, epochs=200, batch_size=128):\n",
    "    print(f\"\\n=== Training model {model_id} ===\")\n",
    "\n",
    "    # Seeds for reproducibility\n",
    "    torch.manual_seed(model_id)\n",
    "    np.random.seed(model_id)\n",
    "\n",
    "    # Data augmentation as in Ovadia et al.\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_set = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=True, download=True, transform=transform_train\n",
    "    )\n",
    "    test_set = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=False, download=True, transform=transform_test\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    # Build model\n",
    "    model = build_resnet18_cifar().to(device)\n",
    "\n",
    "    # Adam optimizer (as required)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # --------------------------\n",
    "    # Training loop\n",
    "    # --------------------------\n",
    "    pbar = tqdm(range(epochs), leave=False)\n",
    "    for epoch in pbar:\n",
    "        model.train()\n",
    "        update_lr(optimizer, epoch, initial_lr)\n",
    "\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            _, pred = out.max(1)\n",
    "            correct += pred.eq(y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "        acc = correct / total * 100\n",
    "        pbar.set_description(f\"Epoch {epoch:3d} | Loss {total_loss/total:.4f} | Acc {acc:.2f}%\")\n",
    "\n",
    "    # Save\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, f\"model_{model_id}.pth\"))\n",
    "    print(f\"Saved model {model_id} â†’ {save_dir}/model_{model_id}.pth\")\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# Train an ensemble of N models\n",
    "# ----------------------------------------\n",
    "\n",
    "def train_ensemble(\n",
    "    n_models=5,\n",
    "    save_dir=\"./ensemble_resnet18_cifar\",\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    for model_id in range(n_models):\n",
    "        train_one_model(model_id, save_dir, device=device)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_ensemble(n_models=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff11a997-8311-4a49-9820-90699423c152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_kernel",
   "language": "python",
   "name": "torch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
